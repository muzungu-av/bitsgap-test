use crate::{database::save_klines, parser::kline::Kline};
use once_cell::sync::Lazy;
use sqlx::{Pool, Sqlite};
use std::{collections::HashMap, sync::Arc};
use tokio::sync::Mutex;
use tracing::{debug, error, info, Level};

pub struct CandleAggregator {
    chain: Mutex<FilterChain>, // –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π Mutex
    db_pool: Arc<Option<Pool<Sqlite>>>,
}

/*
    An implementation of a slightly modified ‚ÄúChain of Duty‚Äù template, in which chains are built dynamically
    and correspond to the combination of timeframes and characters in env. Each handler processes its own piece of data
    passing the unsuitable ones to the next handler, so that they work like a filter system (or sieve).
    It takes the data it needs and performs the necessary actions with it (stores it in the database).

    It was designed with the ability to handle mixed data from multiple url's (different pairs and timeframes),
    sorting each data series by a separate handler, However, this has not been tested....
*/
impl CandleAggregator {
    pub fn get_instance() -> &'static Arc<Self> {
        static INSTANCE: Lazy<Arc<CandleAggregator>> = Lazy::new(|| {
            Arc::new(CandleAggregator {
                chain: Mutex::new(FilterChain::new()),
                db_pool: Arc::new(None),
            })
        });
        &INSTANCE
    }

    pub async fn build_handlers(
        self: Arc<Self>, // –ü–µ—Ä–µ–¥–∞—ë–º self –∫–∞–∫ Arc<Self>
        keys: &[(String, String)],
        db_pool: Arc<Pool<Sqlite>>, // –ü–µ—Ä–µ–¥–∞—ë–º –ø–æ –∑–Ω–∞—á–µ–Ω–∏—é, –∞ –Ω–µ –ø–æ —Å—Å—ã–ª–∫–µ!
    ) {
        println!("***** pub async fn build_handlers");
        let db_pool = db_pool.clone(); // üî• –ö–ª–æ–Ω–∏—Ä—É–µ–º, —á—Ç–æ–±—ã –Ω–µ –¥–µ—Ä–∂–∞—Ç—å —Å—Å—ã–ª–∫—É!

        // –ö–ª–æ–Ω–∏—Ä—É–µ–º self –¥–æ —Ç–æ–≥–æ, –∫–∞–∫ –±—É–¥–µ–º –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –≤ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –∑–∞–¥–∞—á—É
        let self_clone = Arc::clone(&self);

        let handler = Arc::new(move |data: &mut HashMap<(String, String), Vec<Kline>>| {
            println!("Data: {:?}", data);

            let mut keys_to_remove = Vec::new();
            println!("***** for (key, klines) in data.iter()...");
            for (key, klines) in data.iter() {
                let key = key.clone();
                let klines = klines.clone();
                keys_to_remove.push(key.clone());

                let db_pool = db_pool.clone();
                let self_clone = Arc::clone(&self_clone); // –ö–ª–æ–Ω–∏—Ä—É–µ–º self –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏
                println!("***** About to spawn task...");
                tokio::spawn(async move {
                    println!("***** 5");
                    let mut chain = self_clone.chain.lock().await; // –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π self
                    if let Some(last_kline) = klines.iter().max_by_key(|k| k.utc_begin) {
                        chain
                            .update_last_kline(key.clone(), last_kline.clone())
                            .await;
                    }

                    if let Err(e) = save_klines(&db_pool, &klines).await {
                        error!("Failed to save klines: {}", e);
                    }
                });
            }

            for key in keys_to_remove {
                data.remove(&key);
            }

            true
        });

        // –ö–ª–æ–Ω–∏—Ä—É–µ–º self –ø—Ä–∏ –≤—ã–∑–æ–≤–µ add_handler
        self.chain.lock().await.add_handler(handler);
    }

    pub async fn http_response_process(
        &self,
        mut grouped_kline: HashMap<(String, String), Vec<Kline>>,
    ) {
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º block_in_place –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –≤ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
        tokio::task::block_in_place(|| {
            let chain = self.chain.blocking_lock(); // –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –¥–æ—Å—Ç—É–ø
            chain.execute(&mut grouped_kline);
        });
    }
}

pub struct FilterChain {
    handlers: Vec<Arc<dyn Fn(&mut HashMap<(String, String), Vec<Kline>>) -> bool + Send + Sync>>,
    last_klines: Mutex<HashMap<(String, String), Kline>>, // —Ç—É—Ç —Ö—Ä–∞–Ω–∏–º –≤—Å–µ –ø–æ—Å–ª–µ–¥–Ω–∏–µ Kline
}

impl FilterChain {
    pub fn new() -> Self {
        FilterChain {
            handlers: Vec::new(),
            last_klines: Mutex::new(HashMap::new()),
        }
    }

    pub async fn update_last_kline(&self, key: (String, String), kline: Kline) {
        let mut last_klines = self.last_klines.lock().await;
        last_klines.insert(key, kline);
    }

    pub async fn get_last_kline(&self, key: &(String, String)) -> Option<Kline> {
        let last_klines = self.last_klines.lock().await;
        last_klines.get(key).cloned()
    }

    pub fn add_handler(
        &mut self,
        handler: Arc<dyn Fn(&mut HashMap<(String, String), Vec<Kline>>) -> bool + Send + Sync>,
    ) {
        self.handlers.push(handler);
    }

    pub fn execute(&self, grouped_kline: &mut HashMap<(String, String), Vec<Kline>>) {
        for handler in &self.handlers {
            if handler(grouped_kline) {}
        }
    }
}
